[Auto-generated transcript. Edits may have been applied for clarity.]
Stores does the data center use? Yeah, the data center uses a sand for shared storage. So these are the SANS that I'm showing you in the slide right now.

So the HP Nimble is the sand, the Dell Compellant's the same.

So yeah, Assam.

So I talked about the HP. So we use a product called Dell Compellant for the file servers. It's not as fast as the HP, so it's a cheaper and it's uh it's good for workloads like file services where there's not a lot of stuff going on all the time.

Users grade 50, which is similar to rate six so it's Rage 50 is range five plus 10. So it's rate five twice. I'm doing a bad job of explaining it. You'll have to look that one up. I'm not good at describing that.

And we use a technology called iSCSI to connect the storage to host servers So… iSCSI is a protocol that runs, it can run over ethernet. So there's an ethernet cable between those physical host servers and the storage server that connects it to the storage.

And then we use Dell Component again for our backup system 380 terabytes of capacity, again, RAID 50 and connected via iSCSI. Now, this is what the storage systems look like.

So these are just boxes of hard drives. There's some ssds and some hard drives in this This provides the storage for all the VMs.

The one on the right here is the Dell Compellant storage, which is slower than the storage here on the left but also significantly cheaper.

All right, I have a demo for this one too.

Okay, so this is the interface, the management interface to the storage where you can just you know get a general idea of what's going on with the storage array at any time. So it looks like we have a capacity of about 246 terabytes

The storage is 54% used right now. And this is truly the interesting part. So you can see deduplication is saving us 71.7 terabytes. So if we didn't have deduplication on this array, we would be using an additional 71 terabytes.

And the compression, it's saving us 44.8 terabytes. So deduplication and compression.

And I'll talk about those again when I talk about backup save you a lot of space.

In your backend storage. With this interface, we can evaluate the performance of the array, it looks like the latency is the length of time it takes the array to respond to a request. And you can see that it it rarely goes over two milliseconds.

For all of those VMs talking to the storage can ask for stuff and the array capable of responding within about two milliseconds.

The IOPS here is the amount of the amount of input-output operations per second. So at its peak over the last hour, it looks like about it's doing about 20,000 operations per second So these things are very fast.

Here's the throughput that it's getting. So it peaked at about 2000 megabytes per second And then the cash hit rate down here. So I mentioned that this is a combination of SSD, and spinning magnetic traditional drives this is the

Percent of the time that the data that a user asks for is on the SSD.

So the system is really good at predicting and keeping on the SSDs what people want. So if something is accessed often, it's going to move it up to the SSD.

So that's what enables it to respond so quick. All right, so that covers storage.

So now networking, again, I'm not a network specialist and we have an entire department that does networking, but I'll go over some real high level stuff here. So Newcomb Hall, I think I mentioned this before, serves as the network hub

For campus that's right there on the quad. That's where the internet connection comes in from outside. And then the administrative center over here where the main data center is, is connected via four 10 gigabit interfaces. I think there's more now

At this point, but there are at least four. And these are independent underground paths. I think one of them goes through the law school. One of them might go through Cherry Hall.

Over there, but multiple connections to the data center in case one of those fiber paths gets cut Now, the smart row I was showing you earlier if I had a picture of the back of them with the door open

You could see the top of rack switches in them. So there's two switches in a rack.

That we wire the servers with both switches. So again, more redundancy. If one of those switches were to go down.

The server could communicate through the other switch. So each host is connected via two 10 gigabit interfaces, which Yeah, provide that redundancy I just talked about, but also provide some really high throughput.

All right, on to backup. For backup, we use a product called Commvault.

And we don't write our backups to tape anymore. We write them to hard drives now. And it makes it a lot faster to do, well, to do the backup and to do the recovery We do nightly incremental backups. So every night around like 8 p.m, it backs up the changes that have happened that day.

And then every week it does, I think that's on Saturday night, it does a full backup of everything.

And then finally, once a month, we write backups up to Amazon AWS.

They have a tier called deep archive that only costs about a dollar a terabyte per month.

Which is very, very affordable way to place the backup. The data that's very redundant and redundant and secure. Let me show you that backup system.

So this is the interface to Commvault. It's backing up 943 VMs now. That number is so high, I believe, because it still sees ones that it's backed up in the past.

So I'll click on these 943 VMs here and try to find one.

That's active right now.

One, two. Okay, so here's one that's active. This is the campus print server. So if you print to a printer and one of the computer labs. This is the server that the job goes through.

So looks like this server has lots of recovery points. Today's the 25th, so we have a backup from last night.

At 8 p.m. We have a backup from, let's say, last Thursday at 8 p.m so let's say that somebody deleted something between then and now and we need to restore it. We just find the date.

Click Restore. Browse the files on the system.

And you can see it shows you the drives on the system here, like the C drive is here program files directory Let's go in Hewlett Packard.

Go a level further. And then these are all files in that directory. So say this particular file got deleted and it was extremely important.

We would just select the file and click restore. And it would restore that file to where it was on the running system or allow you to download it and copy it there yourself.

So that's because it's on that disc two, it's much easier and quicker to do this than have to go and retrieve a tape drive from a maybe a cabinet across campus where you keep them.

So you can see this software is really powerful. I can show you Yeah, here we go.

This is the library that it's running. So it's a total capacity of 447 teraby Free space, almost 27 deduplication savings, so 90%. We're saving 90% of our space by not storing the same document twice. So that's the deduplication technology that I was

Talking about earlier. All sorts of other things you can look at.

In this, how many jobs are running right now? How many jobs have been successful? We get emails.

From all of our monitoring tools. Also, when stuff like this fails and you can fail hop in here and see why it fails.

Why it failed in tow. Fix it and make sure that all the jobs are successful moving forward there.

Here's a neat little graph or neat little thing down here. It shows you the top five largest servers. So KCDS Santa. It's a dental school server that just that server alone has 80.45 terabytes so that's a very, very, very large server. So you can see our top five servers are all dental school

Related servers they have some very large data down there.

I got one more thing here. I mentioned we copy our backups once a month to the cloud. So this is that cloud copy. So we're using 1.43 petabytes of space up in Amazon to keep off-site backups.

That's pretty much the most interesting stuff in the most interesting Commvault interface there.

I thought I had a slide on the monitoring tools we use. We use a tool called Zabix.

To monitor the server. So there's a little agent that small piece of software that's installed on the servers automatically.

Typically, when we spin up a new server and that piece of software monitors services.

On the server and alerts us with email messages and a dashboard if servers go down so say say a server is running really low on disk space.

Will get an email will get an email saying the server is below 5% and maybe another one when it's below like 1%. So it gives you a little warning. We can go in there and see what's going on, whether we need to

Delete data on that server or whether or not we need to.

Expand the drive. I think that about covers it.

Yeah. If anybody has any… Any questions? Okay, looks like there's one apparent in chat here.

How many servers are deployed in the production site and the DR site? So I have a slide on that. Let's see.

Here we go. So servers in production and DR looks like At least at the time that I created this slide, it was 421 to the production site.

And 95 in the Newcomb all site. I'll put my email address in the chat.

Here. When we used to do these in person, there'd be a component of it where you could come over and actually see these technologies. So if anybody's interested in taking a look at the data center and hearing about it in person.

Feel free to write me and we can set up a time for you to come over and take a look. So any other cool automation technologies used?

Automation. There's a lot of stuff that's automated, most of it on the Windows side and less of it on the Linux side.

Automations that spin up new servers like we've got images of servers where we can say, give us a new server, Windows Server 2019 And it can spin it up in just a few minutes, maybe five minutes from the time you decide you want it till the time it's up available.

And ready to go. We also have a system that we use to build desktop computers, laptops.

Both for Windows and for Linux to just build a base system and then deploy the software that is required and that the user needs.

To those systems. So would you say that all those VMs are usually running

Yeah, yeah. The VMs, I mean, the VMs are up all the time. And, you know, typically they're not doing very much at any particular time. It's what enables us to have dozens of VMs on the same host is that

Typically, most of them sit there doing very little it has the capability.

We have the capability of moving VMs around, like I showed earlier. So if one of them is using that particularly large amount of CPU, we can move that to a host and maybe that host only has 10 VMs on it.

But another host that has VMs that aren't very active might have 50 VMs on it.

So I think the last thing that I'll say, just stress the importance of virtualization and what we do now. Recall these eight hosts here. This is an older picture.

Are running hundreds of virtual machines on them when before you would have If you had 400 servers, you would have 400 of these in a data center, you know, obviously producing a lot more heat and needing more cooling, needing more power

And just more difficult to manage. So having this set up has made system administration significantly easier.

Any more questions?

I don't see any other questions, Frank.

Okay. Like I said, if anybody's interested in coming over and seeing some of this stuff in person, just shoot me an email and we can we can definitely set up a time to do that.

Also, if you have any questions about what I talked about today, I know Professor Choi usually I think gives you a sheet of questions that you need to fill out if you missed anything, feel free to write me and I'd be happy to let you know.

All right. Well, thank you for listening.

Yeah, thank you, Frank. Thank you for your time and the session for taking us through the data center summary. It was a great session. Thank you.

Yeah. You bet. All right. I'll talk to you later and hopefully hear from a few of you.

Thank you. Have a good day. You too.

Have a

